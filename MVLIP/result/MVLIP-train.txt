words.txt에서 82115개 클래스 매핑을 로딩했습니다.
words.txt에서 82115개 클래스 매핑을 로딩했습니다.
클래스 수: 1000
훈련 샘플 수: 34745
검증 샘플 수: 3923
클래스 폴더명 (처음 10개): ['n01440764', 'n01443537', 'n01484850', 'n01491361', 'n01494475', 'n01496331', 'n01498041',
'n01514668', 'n01514859', 'n01518878']
클래스 이름 (처음 10개): ['tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead', 'electric ray', 'stingray', 'cock', 'hen', 'ostrich']
훈련 배치 수: 1085
검증 배치 수: 123
이미지 배치 크기: torch.Size([32, 3, 224, 224])
텍스트 배치 크기: torch.Size([32, 77])
라벨 배치 크기: torch.Size([32])
Epoch 1/20: 100%|██████████████████████████████████████████████████████| 1085/1085 [04:16<00:00,  4.23it/s, loss=0.227]Epoch 1, Average Loss: 2.3315
새로운 최고 성능 모델 저장: 2.3315
Epoch 2/20: 100%|██████████████████████████████████████████████████████| 1085/1085 [04:14<00:00,  4.26it/s, loss=0.162]Epoch 2, Average Loss: 0.2927
새로운 최고 성능 모델 저장: 0.2927
Epoch 3/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:15<00:00,  4.25it/s, loss=0.0744]Epoch 3, Average Loss: 0.1800
새로운 최고 성능 모델 저장: 0.1800
Epoch 4/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:08<00:00,  4.37it/s, loss=0.0342]Epoch 4, Average Loss: 0.1452
새로운 최고 성능 모델 저장: 0.1452
Epoch 5/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.34it/s, loss=0.00836]Epoch 5, Average Loss: 0.1148
새로운 최고 성능 모델 저장: 0.1148
Epoch 6/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.34it/s, loss=0.0135]Epoch 6, Average Loss: 0.1016
새로운 최고 성능 모델 저장: 0.1016
Epoch 7/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.0301]Epoch 7, Average Loss: 0.0868
새로운 최고 성능 모델 저장: 0.0868
Epoch 8/20: 100%|██████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.138]Epoch 8, Average Loss: 0.0815
새로운 최고 성능 모델 저장: 0.0815
Epoch 9/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:08<00:00,  4.36it/s, loss=0.00278]Epoch 9, Average Loss: 0.0733
새로운 최고 성능 모델 저장: 0.0733
Epoch 10/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.133]Epoch 10, Average Loss: 0.0638
새로운 최고 성능 모델 저장: 0.0638
Epoch 11/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:09<00:00,  4.35it/s, loss=0.0628]Epoch 11, Average Loss: 0.0580
새로운 최고 성능 모델 저장: 0.0580
Epoch 12/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.0538]Epoch 12, Average Loss: 0.0528
새로운 최고 성능 모델 저장: 0.0528
Epoch 13/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.0923]Epoch 13, Average Loss: 0.0486
새로운 최고 성능 모델 저장: 0.0486
Epoch 14/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:10<00:00,  4.33it/s, loss=0.0612]Epoch 14, Average Loss: 0.0451
새로운 최고 성능 모델 저장: 0.0451
Epoch 15/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:11<00:00,  4.31it/s, loss=0.093]Epoch 15, Average Loss: 0.0437
새로운 최고 성능 모델 저장: 0.0437
Epoch 16/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:16<00:00,  4.23it/s, loss=0.0045]Epoch 16, Average Loss: 0.0426
새로운 최고 성능 모델 저장: 0.0426
Epoch 17/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:12<00:00,  4.30it/s, loss=0.0552]Epoch 17, Average Loss: 0.0399
새로운 최고 성능 모델 저장: 0.0399
Epoch 18/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:12<00:00,  4.30it/s, loss=0.0129]Epoch 18, Average Loss: 0.0370
새로운 최고 성능 모델 저장: 0.0370
Epoch 19/20: 100%|████████████████████████████████████████████████████| 1085/1085 [04:15<00:00,  4.24it/s, loss=0.0452]Epoch 19, Average Loss: 0.0399
Epoch 20/20: 100%|█████████████████████████████████████████████████████| 1085/1085 [04:08<00:00,  4.36it/s, loss=0.213]Epoch 20, Average Loss: 0.0362
새로운 최고 성능 모델 저장: 0.0362
훈련 완료. 모델이 ./checkpoints3(MVLIP-fp32)에 저장되었습니다.


- Eval
Generating embeddings for 10000 class prompts (Total Classes: 1000).
Encoding text prompts: 100%|███████████████████████████████████████████████████████████| 79/79 [00:04<00:00, 17.48it/s]Starting zero-shot classification evaluation on 3923 images...
Initial GPU Memory Usage: 2535.55 MB
Evaluating images: 100%|█████████████████████████████████████████████████████████████| 123/123 [00:06<00:00, 19.79it/s]
--- Evaluation Summary ---
Total Samples Evaluated: 3923
Total Evaluation Time: 6.26 seconds
Average Evaluation Loss: 1.1713
Throughput: **626.35 samples/second**
Max GPU Memory Usage During Evaluation: 2546.57 MB (after encoding images)
    
    ```
                                    **precision    recall  f1-score   support          
                          accuracy                           0.75      3923
                         macro avg       0.77      0.75      0.73      3923
                      weighted avg       0.78      0.75      0.74      3923**
    ```